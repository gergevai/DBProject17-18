{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Get Started with PySpark and Jupyter Notebook in 3 Minutes](https://blog.sicara.com/get-started-pyspark-jupyter-guide-tutorial-ae2fe84f594f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "  * #### Part 1: Essential Libraries to\n",
    "    * Find Spark Installation &nbsp;&nbsp;&nbsp;&nbsp;>>> **import** findspark\n",
    "    * Initiate a Spark Instance &nbsp;>>> **findspark.init()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark; findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * #### Part 2: Importing Essential pyspark Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark import SQLContext\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Spark and SQL Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local[*]\", \"db2-q2-spark-df-a\")\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset from csv file --  SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, timestamp: timestamp, kilometers: double, region_id: int]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_records = sqlContext.read.load(\"db2_project_data.csv\", format='com.databricks.spark.csv', header='true', inferSchema='true')\n",
    "log_records.persist() # Make it persistent to both MEMORY (if it \"fits\") and DISK to speed up computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Statistics for our Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1. Number of Distinct Cars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation took: 0.7978129386901855  seconds to complete.\n",
      "The number of distinct cars is:  1596\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "num = log_records.select('ID').distinct().count()\n",
    "\n",
    "print ('Operation took:', time.time() - st, ' seconds to complete.')\n",
    "print ('The number of distinct cars is: ', num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2. Number of Cars that Passed each Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Computation Time: 0.010528326034545898  seconds.\n",
      "The Number of Cars that Passed each Region:\n",
      "+---------+---------+\n",
      "|region_id|count(ID)|\n",
      "+---------+---------+\n",
      "|       31|   108261|\n",
      "|       53|   108960|\n",
      "|       34|   108540|\n",
      "+---------+---------+\n",
      "only showing top 3 rows\n",
      "\n",
      "None\n",
      "Cumulative Computation Time: 0.2912750244140625  seconds.\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "res = log_records.groupby(\"region_id\").agg({'ID': 'count'})\n",
    "fn = time.time() - st\n",
    "\n",
    "print ('Query Computation Time:', fn, ' seconds.')\n",
    "print ('The Number of Cars that Passed each Region:')\n",
    "print (res.show(3))\n",
    "print ('Cumulative Computation Time:', time.time() - st, ' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3. Traffic Percentage in each Region "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach - Using Dataframe Operations\n",
    "  * Using Native SQLContext Functions we group by the region id and count the number of cars that passed from that single region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Computation Time: 0.11533498764038086  seconds.\n",
      "The Traffic Percentage in each Region:\n",
      "+---------+------------------+\n",
      "|region_id|        percentage|\n",
      "+---------+------------------+\n",
      "|       31|1.8480647393665566|\n",
      "|       53|1.8599969887713947|\n",
      "|       34|1.8528273968543243|\n",
      "+---------+------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "None\n",
      "Cumulative Computation Time: 0.37951016426086426  seconds.\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "num = log_records.count()\n",
    "res = log_records.groupby('region_id').agg((count(log_records['ID'])/num*100).alias('percentage'))\n",
    "fn = time.time() - st\n",
    "\n",
    "print ('Query Computation Time:', fn, ' seconds.')\n",
    "print ('The Traffic Percentage in each Region:')\n",
    "print (res.show(3))\n",
    "print ('Cumulative Computation Time:', time.time() - st, ' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4. Kilometer Percentage per Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Computation Time: 1.1453475952148438  seconds.\n",
      "The kilometer Distance Percentage per month:\n",
      "+-----+------------------+\n",
      "|month|        percentage|\n",
      "+-----+------------------+\n",
      "|   12| 13.74256831097875|\n",
      "|    1|14.162338451444722|\n",
      "|    6|13.840445194874022|\n",
      "+-----+------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "None\n",
      "Cumulative Computation Time: 1.3829827308654785  seconds.\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "num = log_records.agg(sum(log_records['kilometers'])).collect()[0][0]\n",
    "res = log_records.groupby(month(log_records['timestamp']).alias('month')).agg((sum(log_records['kilometers'])/num*100).alias('percentage'))\n",
    "fn = time.time() - st\n",
    "\n",
    "print ('Query Computation Time:', fn, ' seconds.')\n",
    "print ('The kilometer Distance Percentage per month:')\n",
    "print (res.show(3))\n",
    "print ('Cumulative Computation Time:', time.time() - st, ' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5. Average Kilometers per Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Computation Time: 0.01503896713256836  seconds.\n",
      "The Average Kilometer Distance in each Region per Month:\n",
      "+---------+-----+-----------------+\n",
      "|region_id|month|   avg_kilometers|\n",
      "+---------+-----+-----------------+\n",
      "|       43|    7|550.0570712663371|\n",
      "|       10|    2|564.7339467337513|\n",
      "|       41|    3|562.3467249354493|\n",
      "+---------+-----+-----------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "None\n",
      "Cumulative Computation Time: 0.6021502017974854  seconds.\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "res = log_records.groupby([log_records['region_id'], month(log_records['timestamp']).alias('month')]).agg(avg(log_records['kilometers']).alias('avg_kilometers'))\n",
    "fn = time.time() - st\n",
    "\n",
    "print ('Query Computation Time:', fn, ' seconds.')\n",
    "print ('The Average Kilometer Distance in each Region per Month:')\n",
    "print (res.show(3))\n",
    "print ('Cumulative Computation Time:', time.time() - st, ' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopping Spark Context... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
